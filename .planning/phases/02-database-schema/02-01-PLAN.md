---
phase: 02-database-schema
plan: 01
type: execute
---

<objective>
Set up Supabase project and create core PostgreSQL schema for Noms.

Purpose: Establish database foundation with user accounts, places, lists, and journal entries that all future API work depends on.
Output: Working Supabase database with core tables, ready for API integration.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-database-schema/DISCOVERY.md
@.planning/phases/01-project-foundation/01-01-SUMMARY.md
@.planning/phases/01-project-foundation/01-02-SUMMARY.md
@PRD.md

**Tech stack available:**
- FastAPI backend at backend/app/main.py
- Python venv + requirements.txt
- Environment variables via .env

**Key decisions from DISCOVERY.md:**
- Reference Supabase auth.users (don't duplicate)
- Hybrid Google Places storage (cache display fields + place_id)
- Supabase Storage URLs for photos (not BLOBs)
- Implicit default list (list_id NULL), explicit themed lists
- TIMESTAMPTZ for all timestamps
- Supabase CLI migrations (not Alembic)

**Data model:**
- users → extends auth.users
- places → cached Google Places data with place_id
- lists → user-created themed collections
- saved_places → many-to-many (users, places, lists)
- journal_entries → photo-first with optional rating
</context>

<tasks>

<task type="checkpoint:human-action" gate="blocking">
  <action>Create Supabase project and retrieve connection credentials</action>
  <instructions>
I need to configure the Supabase backend connection, but this requires a Supabase account and project.

**Steps:**
1. Go to https://supabase.com
2. Sign up or log in
3. Click "New Project"
4. Fill in:
   - Project name: "Noms"
   - Database password: (generate strong password - save it!)
   - Region: Choose closest to you
5. Wait 2-3 minutes for project to initialize
6. Go to Project Settings → API
7. Copy these values:
   - Project URL (e.g., https://xxxxx.supabase.co)
   - anon/public key (starts with "eyJ...")
   - service_role key (starts with "eyJ..." - keep secret!)
8. Go to Project Settings → Database
9. Copy:
   - Connection string (URI format)

Once you have these credentials, I'll update the backend configuration.
  </instructions>
  <verification>User provides Supabase project URL and connection credentials</verification>
  <resume-signal>Paste your credentials in this format:
```
PROJECT_URL=https://xxxxx.supabase.co
ANON_KEY=eyJ...
SERVICE_KEY=eyJ...
DATABASE_URL=postgresql://postgres:[password]@db.xxxxx.supabase.co:5432/postgres
```
</resume-signal>
</task>

<task type="auto">
  <name>Task 2: Create core database schema with Supabase migrations</name>
  <files>backend/supabase/migrations/20260113000001_create_core_schema.sql, backend/.env.example, backend/requirements.txt</files>
  <action>
**Add Supabase client to requirements:**

Update backend/requirements.txt to add:
```
supabase==2.3.0
```

**Update .env.example with Supabase credentials:**

Add to backend/.env.example:
```
# Supabase (configured in Phase 2)
SUPABASE_URL=https://xxxxx.supabase.co
SUPABASE_ANON_KEY=your_anon_key_here
SUPABASE_SERVICE_KEY=your_service_key_here
```

**Create migration directory structure:**

```bash
mkdir -p backend/supabase/migrations
```

**Create migration file:**

Create backend/supabase/migrations/20260113000001_create_core_schema.sql with complete schema:

```sql
-- Core schema for Noms app
-- Phase 2: Database Schema

-- Extension for UUID generation
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Users table (extends Supabase auth.users)
CREATE TABLE users (
  id UUID PRIMARY KEY REFERENCES auth.users(id) ON DELETE CASCADE,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Places table (cached Google Places data)
CREATE TABLE places (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  google_place_id TEXT UNIQUE NOT NULL,
  name TEXT NOT NULL,
  address TEXT,
  photo_reference TEXT,
  types TEXT[],
  last_fetched_at TIMESTAMPTZ,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  CONSTRAINT valid_google_place_id CHECK (length(google_place_id) > 0)
);

-- Lists table (user-created themed collections)
CREATE TABLE lists (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  name TEXT NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  CONSTRAINT valid_list_name CHECK (length(trim(name)) > 0)
);

-- Saved places (many-to-many: users, places, lists)
-- list_id NULL = default "Saved" list
CREATE TABLE saved_places (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  place_id UUID NOT NULL REFERENCES places(id) ON DELETE CASCADE,
  list_id UUID REFERENCES lists(id) ON DELETE SET NULL,
  saved_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(user_id, place_id, list_id)
);

-- Journal entries (photo-first food memories)
CREATE TABLE journal_entries (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  place_id UUID REFERENCES places(id) ON DELETE SET NULL,
  photo_url TEXT NOT NULL,
  rating SMALLINT CHECK (rating BETWEEN 1 AND 5),
  note TEXT,
  eaten_at TIMESTAMPTZ DEFAULT NOW(),
  created_at TIMESTAMPTZ DEFAULT NOW(),
  CONSTRAINT valid_photo_url CHECK (length(photo_url) > 0)
);

-- Comments for documentation
COMMENT ON TABLE users IS 'App user profiles extending Supabase auth.users';
COMMENT ON TABLE places IS 'Cached Google Places data with place_id for refresh';
COMMENT ON TABLE lists IS 'User-created themed restaurant collections';
COMMENT ON TABLE saved_places IS 'User saved places (list_id NULL = default Saved)';
COMMENT ON TABLE journal_entries IS 'Photo-first food journal with optional rating';
```

**Create migration application script:**

Create backend/supabase/apply_migration.py:
```python
"""
Apply Supabase migrations manually
Usage: python supabase/apply_migration.py
"""
import os
from supabase import create_client

def apply_migration():
    url = os.getenv("SUPABASE_URL")
    key = os.getenv("SUPABASE_SERVICE_KEY")

    if not url or not key:
        print("Error: SUPABASE_URL and SUPABASE_SERVICE_KEY must be set")
        return

    client = create_client(url, key)

    # Read migration file
    with open("supabase/migrations/20260113000001_create_core_schema.sql") as f:
        sql = f.read()

    # Execute migration
    try:
        client.postgrest.rpc("exec_sql", {"sql": sql}).execute()
        print("✅ Migration applied successfully")
    except Exception as e:
        print(f"❌ Migration failed: {e}")
        print("Note: Apply migration via Supabase Dashboard SQL Editor instead")

if __name__ == "__main__":
    apply_migration()
```

**Document migration in backend/README.md:**

Add "Database Setup" section:
```markdown
## Database Setup

### Apply Migrations

**Option 1: Supabase Dashboard (Recommended)**
1. Go to Supabase Dashboard → SQL Editor
2. Copy contents of `supabase/migrations/20260113000001_create_core_schema.sql`
3. Paste and run

**Option 2: Python Script**
```bash
cd backend
source venv/bin/activate
python supabase/apply_migration.py
```

### Verify Schema

Check tables created:
```sql
SELECT table_name FROM information_schema.tables
WHERE table_schema = 'public';
```

Expected tables: users, places, lists, saved_places, journal_entries
```

DO NOT apply the migration automatically - user will run it after reviewing. DO NOT create actual .env file with credentials (security - use .env.example only).
  </action>
  <verify>ls backend/supabase/migrations/ shows SQL file, cat backend/requirements.txt includes supabase, backend/.env.example has Supabase fields</verify>
  <done>Migration file created with all 5 tables (users, places, lists, saved_places, journal_entries), requirements.txt has supabase client, .env.example documents Supabase config, README has migration instructions</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Supabase project created (user confirmation)
- [ ] backend/.env.example includes Supabase config fields
- [ ] backend/requirements.txt includes supabase client
- [ ] backend/supabase/migrations/*.sql contains complete schema
- [ ] Migration creates 5 tables with correct relationships
- [ ] backend/README.md documents migration steps
</verification>

<success_criteria>

- All tasks completed
- Supabase project exists with credentials
- Core schema migration file ready to apply
- Backend configured to connect to Supabase
- Migration instructions documented
</success_criteria>

<output>
After completion, create `.planning/phases/02-database-schema/02-01-SUMMARY.md`:

# Phase 2 Plan 1: Database Foundation Summary

**Set up Supabase project and created core PostgreSQL schema**

## Accomplishments

- Created Supabase project with connection credentials
- Designed complete database schema for Noms (5 tables)
- Created SQL migration file with users, places, lists, saved_places, journal_entries
- Added Supabase Python client to backend dependencies
- Updated .env.example with Supabase configuration
- Documented migration application steps in backend/README.md

## Files Created/Modified

- `backend/supabase/migrations/20260113000001_create_core_schema.sql` - Complete schema DDL
- `backend/supabase/apply_migration.py` - Optional Python migration script
- `backend/requirements.txt` - Added supabase==2.3.0
- `backend/.env.example` - Added SUPABASE_URL, SUPABASE_ANON_KEY, SUPABASE_SERVICE_KEY
- `backend/README.md` - Added Database Setup section with migration instructions

## Decisions Made

- Used Supabase for hosted PostgreSQL + Auth + Storage
- Schema follows DISCOVERY.md design: hybrid Google Places caching, implicit default lists
- Migration file uses plain SQL (Supabase standard, not Alembic)
- Applied via Supabase Dashboard SQL Editor (recommended) or Python script (alternative)
- All tables use UUID primary keys (Supabase default)
- CASCADE deletes on user references (proper cleanup)
- SET NULL on optional foreign keys (journal entries can exist without place)

## Issues Encountered

None

## Next Step

Ready for 02-02-PLAN.md (Database Optimization)
</output>
